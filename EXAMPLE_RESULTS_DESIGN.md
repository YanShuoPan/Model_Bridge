# ç¯„ä¾‹çµæœé åŸ·è¡Œç³»çµ±è¨­è¨ˆ

## ğŸ¯ ç›®æ¨™

å„ªåŒ–æ¨è–¦ç³»çµ±çš„è¡¨é”æ–¹å¼ï¼Œåœ¨æ¨è–¦æ–¹æ³•æ™‚ç›´æ¥å±•ç¤ºï¼š
1. ç¯„ä¾‹è³‡æ–™çš„ç°¡è¿°
2. åŸ·è¡Œæ–¹æ³•çš„å¯¦éš›çµæœï¼ˆåœ–è¡¨ã€æŒ‡æ¨™ï¼‰
3. çµæœçš„å°ˆæ¥­è§£é‡‹

**é—œéµå„ªåŒ–**ï¼šé å…ˆåŸ·è¡Œç¯„ä¾‹ï¼Œæ¸›å°‘ GPT token æ¶ˆè€—

---

## ğŸ“ çŸ¥è­˜åº«çµæ§‹è¨­è¨ˆ

```
backend/knowledge_base/
â”œâ”€â”€ methods/
â”‚   â”œâ”€â”€ logistic_regression/
â”‚   â”‚   â”œâ”€â”€ metadata.json              # æ–¹æ³•å…ƒæ•¸æ“š
â”‚   â”‚   â”œâ”€â”€ description.md             # æ–¹æ³•èªªæ˜
â”‚   â”‚   â”œâ”€â”€ tutorial.md                # æ•™å­¸æ–‡æª”
â”‚   â”‚   â””â”€â”€ examples/
â”‚   â”‚       â””â”€â”€ customer_churn/
â”‚   â”‚           â”œâ”€â”€ config.json        # ç¯„ä¾‹é…ç½®
â”‚   â”‚           â”œâ”€â”€ data.csv           # ç¯„ä¾‹æ•¸æ“š
â”‚   â”‚           â”œâ”€â”€ pre_run_results/   # ã€æ–°å¢ã€‘é åŸ·è¡Œçµæœ
â”‚   â”‚           â”‚   â”œâ”€â”€ results.json   # åŸ·è¡Œçµæœæ•¸æ“š
â”‚   â”‚           â”‚   â”œâ”€â”€ figures/       # ç”Ÿæˆçš„åœ–è¡¨
â”‚   â”‚           â”‚   â”‚   â”œâ”€â”€ roc.png
â”‚   â”‚           â”‚   â”‚   â””â”€â”€ confusion_matrix.png
â”‚   â”‚           â”‚   â””â”€â”€ interpretation_guide.md  # çµæœè§£é‡‹æŒ‡å—
â”‚   â”‚           â””â”€â”€ README.md          # ç¯„ä¾‹èªªæ˜
â”‚   â””â”€â”€ dr_ate_cbps/
â”‚       â””â”€â”€ examples/
â”‚           â””â”€â”€ policy_evaluation/
â”‚               â”œâ”€â”€ config.json
â”‚               â”œâ”€â”€ data.csv
â”‚               â””â”€â”€ pre_run_results/
â”‚                   â”œâ”€â”€ results.json
â”‚                   â”œâ”€â”€ figures/
â”‚                   â”‚   â””â”€â”€ balance_plot.png
â”‚                   â””â”€â”€ interpretation_guide.md
```

---

## ğŸ“„ æ–‡ä»¶æ ¼å¼å®šç¾©

### 1. `results.json` - åŸ·è¡Œçµæœæ•¸æ“š

```json
{
  "method_id": "logistic_regression",
  "example_id": "customer_churn",
  "executed_at": "2025-10-13T10:30:00Z",
  "execution_time_seconds": 2.3,
  "metrics": {
    "accuracy": 0.8542,
    "auc": 0.9123,
    "precision": 0.82,
    "recall": 0.78
  },
  "coefficients": {
    "age": {"value": 0.042, "odds_ratio": 1.043, "p_value": 0.001},
    "tenure": {"value": -0.088, "odds_ratio": 0.916, "p_value": 0.003},
    "monthly_charges": {"value": 0.025, "odds_ratio": 1.025, "p_value": 0.012}
  },
  "figures": [
    {
      "filename": "roc.png",
      "path": "backend/knowledge_base/methods/logistic_regression/examples/customer_churn/pre_run_results/figures/roc.png",
      "type": "roc_curve",
      "description": "ROC æ›²ç·šé¡¯ç¤ºæ¨¡å‹å€åˆ†èƒ½åŠ›"
    },
    {
      "filename": "confusion_matrix.png",
      "path": "backend/knowledge_base/methods/logistic_regression/examples/customer_churn/pre_run_results/figures/confusion_matrix.png",
      "type": "confusion_matrix",
      "description": "æ··æ·†çŸ©é™£å±•ç¤ºé æ¸¬æº–ç¢ºåº¦"
    }
  ],
  "summary": {
    "sample_size": 500,
    "variables_used": ["age", "tenure", "monthly_charges", "contract_type"],
    "outcome_variable": "churned",
    "model_performance": "è‰¯å¥½ï¼ŒAUC = 0.91"
  }
}
```

### 2. `interpretation_guide.md` - çµæœè§£é‡‹æŒ‡å—

```markdown
# å®¢æˆ¶æµå¤±é æ¸¬ - çµæœè§£é‡‹æŒ‡å—

## åŸ·è¡Œæ¦‚æ³
- **æ¨£æœ¬æ•¸**ï¼š500 ç­†å®¢æˆ¶è³‡æ–™
- **çµæœè®Šæ•¸**ï¼šæ˜¯å¦æµå¤±ï¼ˆ0=ç•™å­˜, 1=æµå¤±ï¼‰
- **é æ¸¬è®Šæ•¸**ï¼šå¹´é½¡ã€åˆç´„æœŸé™ã€æœˆè²»ç”¨ã€åˆç´„é¡å‹

## é—œéµç™¼ç¾

### 1. æ¨¡å‹æ•´é«”è¡¨ç¾
- **AUC = 0.91**ï¼šæ¨¡å‹å…·æœ‰å„ªç§€çš„å€åˆ†èƒ½åŠ›
- **æº–ç¢ºç‡ = 85.4%**ï¼šæ•´é«”é æ¸¬æº–ç¢ºåº¦è‰¯å¥½

### 2. é‡è¦å½±éŸ¿å› ç´ 

**åˆç´„æœŸé™ï¼ˆtenureï¼‰**
- ä¿‚æ•¸ = -0.088ï¼Œå‹ç®—æ¯” = 0.916
- **è§£é‡‹**ï¼šåˆç´„æœŸé™æ¯å¢åŠ  1 å€‹æœˆï¼Œæµå¤±æ©Ÿç‡ä¸‹é™ç´„ 8.4%
- **æ„ç¾©**ï¼šé•·æœŸå®¢æˆ¶æ›´ä¸å®¹æ˜“æµå¤±

**æœˆè²»ç”¨ï¼ˆmonthly_chargesï¼‰**
- ä¿‚æ•¸ = 0.025ï¼Œå‹ç®—æ¯” = 1.025
- **è§£é‡‹**ï¼šæœˆè²»ç”¨æ¯å¢åŠ  1 å…ƒï¼Œæµå¤±æ©Ÿç‡å¢åŠ ç´„ 2.5%
- **æ„ç¾©**ï¼šé«˜è²»ç”¨å®¢æˆ¶æ›´å®¹æ˜“æµå¤±

**å¹´é½¡ï¼ˆageï¼‰**
- ä¿‚æ•¸ = 0.042ï¼Œå‹ç®—æ¯” = 1.043
- **è§£é‡‹**ï¼šå¹´é½¡æ¯å¢åŠ  1 æ­²ï¼Œæµå¤±æ©Ÿç‡å¢åŠ ç´„ 4.3%
- **æ„ç¾©**ï¼šå¹´é•·å®¢æˆ¶ç•¥å¾®å®¹æ˜“æµå¤±

## åœ–è¡¨è§£è®€

### ROC æ›²ç·š
- AUC = 0.91 è¡¨ç¤ºæ¨¡å‹æœ‰ 91% çš„æ©Ÿç‡æ­£ç¢ºå€åˆ†æµå¤±èˆ‡ç•™å­˜å®¢æˆ¶
- æ›²ç·šè¶Šæ¥è¿‘å·¦ä¸Šè§’ï¼Œæ¨¡å‹è¶Šå¥½

### æ··æ·†çŸ©é™£
- çœŸé™½æ€§ç‡ï¼ˆå¬å›ç‡ï¼‰ï¼š78%
- çœŸé™°æ€§ç‡ï¼š89%
- æ¨¡å‹å°ç•™å­˜å®¢æˆ¶çš„é æ¸¬æ›´æº–ç¢º

## å¯¦å‹™æ‡‰ç”¨å»ºè­°

1. **é‡é»é—œæ³¨é«˜æœˆè²»å®¢æˆ¶**ï¼šæä¾›å„ªæƒ æˆ–å®¢è£½åŒ–æ–¹æ¡ˆ
2. **å¼·åŒ–æ–°å®¢æˆ¶é«”é©—**ï¼šåˆç´„åˆæœŸæä¾›æ›´å¤šæ”¯æ´
3. **å»ºç«‹é è­¦ç³»çµ±**ï¼šç•¶å®¢æˆ¶é¢¨éšªåˆ†æ•¸ > 0.7 æ™‚ä¸»å‹•è¯ç¹«

## å‡è¨­æª¢é©—

æ‰€æœ‰è®Šæ•¸çš„ p-value < 0.05ï¼Œè¡¨ç¤ºå½±éŸ¿å‡é”çµ±è¨ˆé¡¯è‘—æ°´å¹³ã€‚
```

---

## ğŸ”§ å¯¦ä½œæ­¥é©Ÿ

### Step 1: å‰µå»ºé åŸ·è¡Œè…³æœ¬

`backend/scripts/pre_run_examples.py`

```python
"""
é åŸ·è¡Œç¯„ä¾‹æ•¸æ“šä¸¦å„²å­˜çµæœ
"""
import sys
import os
import json
from pathlib import Path
from datetime import datetime

# æ·»åŠ å¾Œç«¯è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent))

from backend.methods.base import METHODS_REGISTRY
import pandas as pd


def pre_run_example(method_id: str, example_path: str):
    """
    é åŸ·è¡Œå–®å€‹ç¯„ä¾‹

    Args:
        method_id: æ–¹æ³• ID
        example_path: ç¯„ä¾‹ç›®éŒ„è·¯å¾‘
    """
    example_dir = Path(example_path)

    # 1. è®€å–é…ç½®
    config_path = example_dir / "config.json"
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)

    # 2. è®€å–æ•¸æ“š
    data_path = example_dir / config["data_source"]
    df = pd.read_csv(data_path)

    # 3. å‰µå»ºè¼¸å‡ºç›®éŒ„
    output_dir = example_dir / "pre_run_results"
    output_dir.mkdir(exist_ok=True)
    figures_dir = output_dir / "figures"
    figures_dir.mkdir(exist_ok=True)

    # 4. åŸ·è¡Œæ–¹æ³•
    method_cls = METHODS_REGISTRY[method_id]
    method = method_cls()

    print(f"åŸ·è¡Œ {method_id} - {config['example_name']}...")

    results = method.run(
        df=df,
        roles=config["roles"],
        params=config.get("parameters", {}),
        out_dir=str(figures_dir)
    )

    # 5. å„²å­˜çµæœ
    results_data = {
        "method_id": method_id,
        "example_id": example_dir.name,
        "executed_at": datetime.now().isoformat(),
        "execution_time_seconds": None,  # å¯ä»¥æ·»åŠ è¨ˆæ™‚
        "metrics": results.get("metrics", {}),
        "coefficients": results.get("coefficients", {}),
        "figures": [],
        "summary": {
            "sample_size": len(df),
            "variables_used": config["roles"].get("X", []),
            "outcome_variable": config["roles"].get("y"),
            "model_performance": results.get("summary_md", "")
        }
    }

    # è™•ç†åœ–è¡¨
    if "figures" in results:
        for fig_path in results["figures"]:
            fig_name = Path(fig_path).name
            results_data["figures"].append({
                "filename": fig_name,
                "path": f"backend/knowledge_base/methods/{method_id}/examples/{example_dir.name}/pre_run_results/figures/{fig_name}",
                "type": Path(fig_name).stem,
                "description": f"{fig_name} åœ–è¡¨"
            })

    # å„²å­˜ results.json
    with open(output_dir / "results.json", 'w', encoding='utf-8') as f:
        json.dump(results_data, f, ensure_ascii=False, indent=2)

    print(f"âœ“ çµæœå·²å„²å­˜åˆ° {output_dir}")

    return results_data


def pre_run_all():
    """é åŸ·è¡Œæ‰€æœ‰ç¯„ä¾‹"""
    # å®šç¾©ç¯„ä¾‹è·¯å¾‘
    examples = [
        {
            "method_id": "logistic_regression",
            "path": "backend/knowledge_base/methods/logistic_regression/examples/customer_churn"
        },
        # æ·»åŠ æ›´å¤šç¯„ä¾‹...
    ]

    for example in examples:
        try:
            pre_run_example(example["method_id"], example["path"])
        except Exception as e:
            print(f"âœ— {example['method_id']} åŸ·è¡Œå¤±æ•—: {e}")


if __name__ == "__main__":
    pre_run_all()
```

---

### Step 2: ä¿®æ”¹ `chat_service.py`

æ·»åŠ è®€å–é åŸ·è¡Œçµæœä¸¦ç”Ÿæˆè§£é‡‹çš„åŠŸèƒ½ï¼š

```python
def load_pre_run_results(method_id: str, example_id: str = None) -> Dict[str, Any]:
    """
    è¼‰å…¥é åŸ·è¡Œçµæœ

    Args:
        method_id: æ–¹æ³• ID
        example_id: ç¯„ä¾‹ IDï¼ˆå¯é¸ï¼Œé è¨­è¼‰å…¥ç¬¬ä¸€å€‹ç¯„ä¾‹ï¼‰

    Returns:
        é åŸ·è¡Œçµæœå­—å…¸
    """
    try:
        # å¦‚æœæ²’æŒ‡å®š example_idï¼Œè¼‰å…¥ç¬¬ä¸€å€‹ç¯„ä¾‹
        if not example_id:
            examples_dir = Path(f"backend/knowledge_base/methods/{method_id}/examples")
            if examples_dir.exists():
                example_id = next(examples_dir.iterdir()).name

        # è®€å– results.json
        results_path = Path(f"backend/knowledge_base/methods/{method_id}/examples/{example_id}/pre_run_results/results.json")

        if not results_path.exists():
            return None

        with open(results_path, 'r', encoding='utf-8') as f:
            results = json.load(f)

        # è®€å–è§£é‡‹æŒ‡å—
        guide_path = results_path.parent / "interpretation_guide.md"
        if guide_path.exists():
            with open(guide_path, 'r', encoding='utf-8') as f:
                results["interpretation_guide"] = f.read()

        return results

    except Exception as e:
        print(f"è¼‰å…¥é åŸ·è¡Œçµæœå¤±æ•—: {e}")
        return None


def generate_result_explanation(results: Dict[str, Any], interpretation_guide: str) -> str:
    """
    ä½¿ç”¨ GPT æ ¹æ“šé åŸ·è¡Œçµæœå’Œè§£é‡‹æŒ‡å—ç”Ÿæˆè§£é‡‹

    Args:
        results: é åŸ·è¡Œçµæœ
        interpretation_guide: è§£é‡‹æŒ‡å—å…§å®¹

    Returns:
        GPT ç”Ÿæˆçš„è§£é‡‹
    """
    try:
        prompt = f"""ä½ æ˜¯çµ±è¨ˆåˆ†æå°ˆå®¶ã€‚è«‹æ ¹æ“šä»¥ä¸‹ç¯„ä¾‹åŸ·è¡Œçµæœï¼Œç”¨ç°¡æ½”æ˜“æ‡‚çš„èªè¨€å‘ç”¨æˆ¶è§£é‡‹ï¼š

**åŸ·è¡Œçµæœæ‘˜è¦ï¼š**
- æ¨£æœ¬æ•¸ï¼š{results['summary']['sample_size']}
- çµæœè®Šæ•¸ï¼š{results['summary']['outcome_variable']}
- é æ¸¬è®Šæ•¸ï¼š{', '.join(results['summary']['variables_used'])}
- ä¸»è¦æŒ‡æ¨™ï¼š{json.dumps(results['metrics'], ensure_ascii=False)}

**è§£é‡‹æŒ‡å—ï¼š**
{interpretation_guide}

è«‹ç”Ÿæˆä¸€æ®µ 150-200 å­—çš„è§£é‡‹ï¼ŒåŒ…æ‹¬ï¼š
1. é€™å€‹ç¯„ä¾‹åœ¨åšä»€éº¼åˆ†æ
2. ä¸»è¦ç™¼ç¾æ˜¯ä»€éº¼ï¼ˆç”¨æ•¸æ“šèªªè©±ï¼‰
3. å°å¯¦å‹™çš„æ„ç¾©

å›ç­”è¦ï¼š
- ç°¡æ½”æ˜ç­
- çªå‡ºé—œéµæ•¸å­—
- é©åˆéçµ±è¨ˆèƒŒæ™¯è®€è€…
"""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯å°ˆæ¥­çš„çµ±è¨ˆåˆ†æè§£èªªå“¡ï¼Œæ“…é•·å°‡è¤‡é›œçµæœè½‰åŒ–ç‚ºæ˜“æ‡‚çš„èªè¨€ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=500
        )

        return response.choices[0].message.content

    except Exception as e:
        print(f"ç”Ÿæˆè§£é‡‹å¤±æ•—: {e}")
        return "ç„¡æ³•ç”Ÿæˆçµæœè§£é‡‹"
```

---

### Step 3: æ›´æ–° `generate_chat_response` å‡½æ•¸

åœ¨æ¨è–¦æ–¹æ³•æ™‚åŒ…å«é åŸ·è¡Œçµæœï¼š

```python
def generate_chat_response(question: str) -> Dict[str, Any]:
    """ç”Ÿæˆå°è©±å¼å›è¦†"""
    question_type = detect_question_type(question)

    if question_type in ["explanation", "how_to", "general"]:
        return answer_question_directly(question, question_type)

    # åˆ†æå•é¡Œ
    analysis = classify_user_question(question)

    response = {
        "question": question,
        "question_type": question_type,
        "analysis": analysis,
        "recommended_methods": [],
        "can_proceed": False,
        "is_direct_answer": False
    }

    recommended_method_id = analysis.get("recommended_method")
    if recommended_method_id and recommended_method_id != "none":
        if recommended_method_id in AVAILABLE_METHODS:
            method_info = AVAILABLE_METHODS[recommended_method_id]

            # ã€æ–°å¢ã€‘è¼‰å…¥é åŸ·è¡Œçµæœ
            pre_run_results = load_pre_run_results(recommended_method_id)

            if pre_run_results:
                # ç”Ÿæˆçµæœè§£é‡‹
                interpretation_guide = pre_run_results.get("interpretation_guide", "")
                result_explanation = generate_result_explanation(pre_run_results, interpretation_guide)

                # æ·»åŠ åˆ°å›è¦†
                method_info["pre_run_results"] = pre_run_results
                method_info["result_explanation"] = result_explanation

            response["recommended_methods"] = [{
                "method_id": recommended_method_id,
                **method_info
            }]
            response["can_proceed"] = True

    return response
```

---

## ğŸ¨ å‰ç«¯é¡¯ç¤ºèª¿æ•´

åœ¨ `frontend/app/page.tsx` ä¸­æ·»åŠ çµæœé¡¯ç¤ºå€å¡Šï¼š

```typescript
// é¡¯ç¤ºé åŸ·è¡Œçµæœ
if (method.pre_run_results) {
  const preRun = method.pre_run_results;

  assistantContent += `\n---\n\n### ğŸ“Š ç¯„ä¾‹åŸ·è¡Œçµæœ\n\n`;
  assistantContent += `**è³‡æ–™é›†**ï¼š${preRun.summary.sample_size} ç­†è³‡æ–™\n\n`;

  // é¡¯ç¤ºæŒ‡æ¨™
  assistantContent += `**ä¸»è¦æŒ‡æ¨™ï¼š**\n`;
  Object.entries(preRun.metrics).forEach(([key, value]) => {
    assistantContent += `â€¢ ${key}: ${value}\n`;
  });

  // é¡¯ç¤ºåœ–è¡¨ï¼ˆæä¾›é€£çµï¼‰
  if (preRun.figures && preRun.figures.length > 0) {
    assistantContent += `\n**åœ–è¡¨ï¼š**\n`;
    preRun.figures.forEach(fig => {
      assistantContent += `â€¢ [æŸ¥çœ‹ ${fig.description}](${API_BASE}/${fig.path})\n`;
    });
  }

  // é¡¯ç¤º GPT è§£é‡‹
  if (method.result_explanation) {
    assistantContent += `\n**ğŸ¯ çµæœè§£é‡‹ï¼š**\n${method.result_explanation}\n`;
  }
}
```

---

## ğŸ“‹ ä½¿ç”¨æµç¨‹

### æ–°å¢æ–¹æ³•æ™‚çš„æ­¥é©Ÿï¼š

1. **æº–å‚™ç¯„ä¾‹æ•¸æ“š** â†’ `data.csv`
2. **å‰µå»ºé…ç½®æ–‡ä»¶** â†’ `config.json`
3. **å¯¦ä½œçµ±è¨ˆæ–¹æ³•** â†’ `your_method.py`
4. **æ’°å¯«è§£é‡‹æŒ‡å—** â†’ `interpretation_guide.md`
5. **åŸ·è¡Œé é‹è¡Œè…³æœ¬**ï¼š
   ```bash
   python backend/scripts/pre_run_examples.py
   ```
6. **æª¢æŸ¥ç”Ÿæˆçš„çµæœ** â†’ `pre_run_results/results.json`
7. **è¨»å†Šåˆ° AVAILABLE_METHODS**

---

## âœ… å„ªé»

1. **æ¸›å°‘ Token æ¶ˆè€—**ï¼šä¸ç”¨æ¯æ¬¡éƒ½è®“ GPT åˆ†æåŸ·è¡Œçµæœ
2. **éŸ¿æ‡‰é€Ÿåº¦å¿«**ï¼šé å…ˆç”Ÿæˆï¼Œç«‹å³å±•ç¤º
3. **çµæœä¸€è‡´æ€§**ï¼šç¯„ä¾‹çµæœå›ºå®šï¼Œè§£é‡‹ç©©å®š
4. **æ˜“æ–¼ç¶­è­·**ï¼šçµæœå’Œè§£é‡‹åˆ†é›¢ï¼Œæ–¹ä¾¿æ›´æ–°
5. **ç”¨æˆ¶é«”é©—ä½³**ï¼šç›´æ¥çœ‹åˆ°å¯¦éš›æ•ˆæœ

---

## ğŸ”„ ä¸‹ä¸€æ­¥

1. ç‚ºç¾æœ‰çš„ `logistic_regression` å’Œ `dr_ate_cbps` å‰µå»ºå®Œæ•´ç¯„ä¾‹
2. åŸ·è¡Œé é‹è¡Œè…³æœ¬ç”Ÿæˆçµæœ
3. æ’°å¯«è§£é‡‹æŒ‡å—
4. æ¸¬è©¦å‰ç«¯é¡¯ç¤º
